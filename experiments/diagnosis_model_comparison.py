#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è¯Šæ–­æ¨¡å‹å¯¹æ¯”å®éªŒ
================
å¯¹æ¯”ä¸‰ç§æ•…éšœè¯Šæ–­æ–¹æ³•:
1. RandomForest (ä¼ ç»Ÿæ–¹æ³•)
2. PINN (ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ)
3. KAN (Kolmogorov-Arnold Networks, 2024)

è¯„ä¼°æŒ‡æ ‡:
- å‡†ç¡®ç‡ (Accuracy)
- å„ç±»åˆ«F1åˆ†æ•°
- è®­ç»ƒæ—¶é—´
- æ¨ç†æ—¶é—´
- å¯è§£é‡Šæ€§

Author: CDC Project
Date: 2026-01-22
"""

import numpy as np
import time
from typing import Dict, List, Tuple
from dataclasses import dataclass
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report
import warnings
warnings.filterwarnings('ignore')

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from diagnosis import PINNDiagnoser, KANDiagnoser, FaultType


@dataclass
class DiagnosisExperimentResult:
    """è¯Šæ–­å®éªŒç»“æœ"""
    method: str
    accuracy: float
    f1_macro: float
    f1_per_class: Dict[str, float]
    train_time: float
    inference_time: float  # ms per sample
    n_parameters: int
    interpretability: str


def generate_synthetic_data(n_samples: int = 2000, noise: float = 0.1) -> Dict[str, np.ndarray]:
    """
    ç”ŸæˆåˆæˆæŸ´æ²¹æœºæ•…éšœè¯Šæ–­æ•°æ®
    
    ç‰¹å¾ (8ç»´):
        0: è½¬é€Ÿ (rpm) - å½’ä¸€åŒ–åˆ°[0,1]
        1: è´Ÿè· (%) - [0,1]
        2: å–·æ²¹æ­£æ—¶ (Â°CA BTDC) - å½’ä¸€åŒ–
        3: å¢å‹å‹åŠ› (bar) - å½’ä¸€åŒ–
        4: è¿›æ°”æ¸©åº¦ (K) - å½’ä¸€åŒ–
        5: ç¯å¢ƒå‹åŠ› (bar) - å½’ä¸€åŒ–
        6: ç‡ƒæ²¹å“è´¨ - [0,1]
        7: è¿è¡Œæ—¶é—´ (h) - å½’ä¸€åŒ–
    
    ç‰©ç†é‡ (3ç»´):
        0: Pmax (bar)
        1: Pcomp (bar)
        2: Texh (Â°C)
    
    æ•…éšœç±»å‹ (4ç±»):
        0: æ­£å¸¸
        1: å–·æ²¹æ­£æ—¶å¼‚å¸¸
        2: æ°”ç¼¸æ³„æ¼
        3: ç‡ƒæ²¹å“è´¨é—®é¢˜
    """
    np.random.seed(42)
    
    n_per_class = n_samples // 4
    features_list = []
    physics_list = []
    labels_list = []
    
    for fault_type in range(4):
        # åŸºç¡€ç‰¹å¾ (æ­£å¸¸å·¥å†µ)
        rpm = np.random.uniform(0.3, 0.9, n_per_class)
        load = np.random.uniform(0.2, 1.0, n_per_class)
        timing = np.random.uniform(0.4, 0.6, n_per_class)  # æ­£å¸¸æ­£æ—¶
        boost = np.random.uniform(0.3, 0.7, n_per_class)
        t_in = np.random.uniform(0.4, 0.6, n_per_class)
        p_amb = np.random.uniform(0.45, 0.55, n_per_class)
        fuel_q = np.random.uniform(0.8, 1.0, n_per_class)  # æ­£å¸¸ç‡ƒæ²¹
        run_h = np.random.uniform(0, 1, n_per_class)
        
        # åŸºç¡€ç‰©ç†é‡
        pmax_base = 120 + 40 * load + 10 * boost
        pcomp_base = 100 + 20 * boost
        texh_base = 280 + 100 * load
        
        if fault_type == 0:  # æ­£å¸¸
            pmax = pmax_base
            pcomp = pcomp_base
            texh = texh_base
            
        elif fault_type == 1:  # å–·æ²¹æ­£æ—¶å¼‚å¸¸
            timing = timing + np.random.choice([-0.2, 0.2], n_per_class)  # æ­£æ—¶åç§»
            timing = np.clip(timing, 0, 1)
            # æ­£æ—¶æå‰: Pmaxå‡é«˜, Texhé™ä½
            # æ­£æ—¶æ»å: Pmaxé™ä½, Texhå‡é«˜
            timing_shift = (timing - 0.5) * 2
            pmax = pmax_base + 15 * timing_shift
            pcomp = pcomp_base
            texh = texh_base - 20 * timing_shift
            
        elif fault_type == 2:  # æ°”ç¼¸æ³„æ¼
            leak_severity = np.random.uniform(0.1, 0.3, n_per_class)
            pmax = pmax_base * (1 - leak_severity)
            pcomp = pcomp_base * (1 - leak_severity * 1.2)
            texh = texh_base + 30 * leak_severity
            
        elif fault_type == 3:  # ç‡ƒæ²¹å“è´¨é—®é¢˜
            fuel_q = np.random.uniform(0.5, 0.8, n_per_class)  # ç‡ƒæ²¹å“è´¨ä¸‹é™
            fuel_effect = 1 - fuel_q
            pmax = pmax_base * (1 - fuel_effect * 0.15)
            pcomp = pcomp_base
            texh = texh_base + 40 * fuel_effect - 20 * fuel_effect
        
        # æ·»åŠ å™ªå£°
        pmax += np.random.randn(n_per_class) * noise * 10
        pcomp += np.random.randn(n_per_class) * noise * 5
        texh += np.random.randn(n_per_class) * noise * 15
        
        # åˆå¹¶ç‰¹å¾
        features = np.stack([rpm, load, timing, boost, t_in, p_amb, fuel_q, run_h], axis=1)
        physics = np.stack([pmax, pcomp, texh], axis=1)
        labels = np.full(n_per_class, fault_type)
        
        features_list.append(features)
        physics_list.append(physics)
        labels_list.append(labels)
    
    # åˆå¹¶å¹¶æ‰“ä¹±
    all_features = np.vstack(features_list)
    all_physics = np.vstack(physics_list)
    all_labels = np.concatenate(labels_list)
    
    indices = np.random.permutation(len(all_labels))
    
    return {
        'features': all_features[indices].astype(np.float32),
        'physics': all_physics[indices].astype(np.float32),
        'labels': all_labels[indices].astype(np.int64)
    }


def train_random_forest(train_data: Dict, test_data: Dict) -> DiagnosisExperimentResult:
    """è®­ç»ƒå¹¶è¯„ä¼°RandomForest"""
    print("\n" + "="*60)
    print("ğŸŒ² è®­ç»ƒ RandomForest (ä¼ ç»ŸåŸºçº¿)")
    print("="*60)
    
    # åˆå¹¶ç‰¹å¾å’Œç‰©ç†é‡ä½œä¸ºè¾“å…¥
    X_train = np.hstack([train_data['features'], train_data['physics']])
    y_train = train_data['labels']
    X_test = np.hstack([test_data['features'], test_data['physics']])
    y_test = test_data['labels']
    
    # è®­ç»ƒ
    start_time = time.time()
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        random_state=42,
        n_jobs=-1
    )
    model.fit(X_train, y_train)
    train_time = time.time() - start_time
    
    # é¢„æµ‹
    start_time = time.time()
    y_pred = model.predict(X_test)
    inference_time = (time.time() - start_time) / len(X_test) * 1000  # ms
    
    # è¯„ä¼°
    accuracy = accuracy_score(y_test, y_pred)
    f1_macro = f1_score(y_test, y_pred, average='macro')
    
    fault_names = ['Normal', 'Timing', 'Leak', 'Fuel']
    f1_per_class = {}
    for i, name in enumerate(fault_names):
        mask = y_test == i
        if mask.sum() > 0:
            f1_per_class[name] = f1_score(y_test == i, y_pred == i)
    
    # ç‰¹å¾é‡è¦æ€§
    feature_names = ['rpm', 'load', 'timing', 'boost', 't_in', 'p_amb', 'fuel_q', 'run_h',
                     'Pmax', 'Pcomp', 'Texh']
    importances = dict(zip(feature_names, model.feature_importances_))
    top_features = sorted(importances.items(), key=lambda x: x[1], reverse=True)[:5]
    
    print(f"  å‡†ç¡®ç‡: {accuracy:.2%}")
    print(f"  F1-macro: {f1_macro:.4f}")
    print(f"  è®­ç»ƒæ—¶é—´: {train_time:.2f}s")
    print(f"  æ¨ç†æ—¶é—´: {inference_time:.4f}ms/sample")
    print(f"  Topç‰¹å¾: {top_features[:3]}")
    
    return DiagnosisExperimentResult(
        method="RandomForest",
        accuracy=accuracy,
        f1_macro=f1_macro,
        f1_per_class=f1_per_class,
        train_time=train_time,
        inference_time=inference_time,
        n_parameters=sum(tree.tree_.node_count for tree in model.estimators_),
        interpretability="ä½: ä»…æä¾›ç‰¹å¾é‡è¦æ€§"
    )


def train_pinn(train_data: Dict, test_data: Dict, epochs: int = 50) -> DiagnosisExperimentResult:
    """è®­ç»ƒå¹¶è¯„ä¼°PINN"""
    print("\n" + "="*60)
    print("ğŸ§  è®­ç»ƒ PINN (ç‰©ç†ä¿¡æ¯ç¥ç»ç½‘ç»œ)")
    print("="*60)
    
    # åˆ›å»ºPINN
    config = {
        'input_dim': 8,
        'hidden_dim': 128,
        'n_blocks': 4,
        'physics_weight': 0.1,
        'lr': 1e-3
    }
    
    pinn = PINNDiagnoser(config)
    
    # è®­ç»ƒ
    start_time = time.time()
    history = pinn.train(train_data, test_data, epochs=epochs, verbose=True)
    train_time = time.time() - start_time
    
    # è¯„ä¼°
    metrics = pinn.evaluate(test_data)
    
    # æ¨ç†æ—¶é—´
    start_time = time.time()
    for i in range(min(100, len(test_data['features']))):
        _ = pinn.diagnose(test_data['features'][i])
    inference_time = (time.time() - start_time) / min(100, len(test_data['features'])) * 1000
    
    # è®¡ç®—F1
    y_test = test_data['labels']
    y_pred = []
    for feat in test_data['features']:
        result = pinn.diagnose(feat)
        y_pred.append(pinn.fault_types.index(result.fault_type))
    y_pred = np.array(y_pred)
    
    f1_macro = f1_score(y_test, y_pred, average='macro')
    
    fault_names = ['Normal', 'Timing', 'Leak', 'Fuel']
    f1_per_class = {}
    for i, name in enumerate(fault_names):
        mask = y_test == i
        if mask.sum() > 0:
            f1_per_class[name] = f1_score(y_test == i, y_pred == i)
    
    print(f"  å‡†ç¡®ç‡: {metrics['accuracy']:.2%}")
    print(f"  F1-macro: {f1_macro:.4f}")
    print(f"  Pmax MAE: {metrics['pmax_mae']:.2f} bar")
    print(f"  è®­ç»ƒæ—¶é—´: {train_time:.2f}s")
    print(f"  æ¨ç†æ—¶é—´: {inference_time:.4f}ms/sample")
    
    return DiagnosisExperimentResult(
        method="PINN",
        accuracy=metrics['accuracy'],
        f1_macro=f1_macro,
        f1_per_class=f1_per_class,
        train_time=train_time,
        inference_time=inference_time,
        n_parameters=sum(p.numel() for p in pinn.model.parameters()),
        interpretability="é«˜: ç‰©ç†æ®‹å·®è§£é‡Šæ•…éšœæœºç†"
    )


def train_kan(train_data: Dict, test_data: Dict, epochs: int = 50) -> DiagnosisExperimentResult:
    """è®­ç»ƒå¹¶è¯„ä¼°KAN"""
    print("\n" + "="*60)
    print("ğŸ”® è®­ç»ƒ KAN (Kolmogorov-Arnold Networks, 2024)")
    print("="*60)
    
    # åˆ›å»ºKAN
    config = {
        'input_dim': 8,
        'hidden_dims': [16, 8],
        'output_dim': 4,
        'grid_size': 5,
        'lr': 1e-3
    }
    
    kan = KANDiagnoser(config)
    
    # è®­ç»ƒ
    start_time = time.time()
    history = kan.train(train_data, test_data, epochs=epochs, verbose=True)
    train_time = time.time() - start_time
    
    # è¯„ä¼°
    metrics = kan.evaluate(test_data)
    
    # æ¨ç†æ—¶é—´
    start_time = time.time()
    for i in range(min(100, len(test_data['features']))):
        _ = kan.diagnose(test_data['features'][i])
    inference_time = (time.time() - start_time) / min(100, len(test_data['features'])) * 1000
    
    # è®¡ç®—F1
    y_test = test_data['labels']
    y_pred = []
    for feat in test_data['features']:
        result = kan.diagnose(feat)
        y_pred.append(kan.fault_types.index(result.fault_type))
    y_pred = np.array(y_pred)
    
    f1_macro = f1_score(y_test, y_pred, average='macro')
    
    fault_names = ['Normal', 'Timing', 'Leak', 'Fuel']
    f1_per_class = {}
    for i, name in enumerate(fault_names):
        mask = y_test == i
        if mask.sum() > 0:
            f1_per_class[name] = f1_score(y_test == i, y_pred == i)
    
    # æå–ç¬¦å·è§„åˆ™
    rules = kan.get_symbolic_rules()
    
    print(f"  å‡†ç¡®ç‡: {metrics['accuracy']:.2%}")
    print(f"  F1-macro: {f1_macro:.4f}")
    print(f"  è®­ç»ƒæ—¶é—´: {train_time:.2f}s")
    print(f"  æ¨ç†æ—¶é—´: {inference_time:.4f}ms/sample")
    print(f"  ç‰¹å¾é‡è¦æ€§: {rules['feature_importance']}")
    
    return DiagnosisExperimentResult(
        method="KAN (2024)",
        accuracy=metrics['accuracy'],
        f1_macro=f1_macro,
        f1_per_class=f1_per_class,
        train_time=train_time,
        inference_time=inference_time,
        n_parameters=kan.model.count_parameters(),
        interpretability="æé«˜: å¯æå–ç¬¦å·åŒ–è¯Šæ–­è§„åˆ™"
    )


def print_comparison_table(results: List[DiagnosisExperimentResult]):
    """æ‰“å°å¯¹æ¯”è¡¨æ ¼"""
    print("\n" + "="*80)
    print("ğŸ“Š è¯Šæ–­æ¨¡å‹å¯¹æ¯”ç»“æœ")
    print("="*80)
    
    print(f"\n{'æ–¹æ³•':<20} {'å‡†ç¡®ç‡':<10} {'F1-macro':<10} {'å‚æ•°é‡':<12} {'è®­ç»ƒæ—¶é—´':<10} {'æ¨ç†æ—¶é—´':<12}")
    print("-"*80)
    
    for r in results:
        print(f"{r.method:<20} {r.accuracy:.2%}     {r.f1_macro:.4f}     {r.n_parameters:<12,} {r.train_time:.2f}s      {r.inference_time:.4f}ms")
    
    print("-"*80)
    
    # æ‰¾æœ€ä½³
    best_acc = max(results, key=lambda x: x.accuracy)
    best_f1 = max(results, key=lambda x: x.f1_macro)
    fastest = min(results, key=lambda x: x.train_time)
    smallest = min(results, key=lambda x: x.n_parameters)
    
    print(f"\nğŸ† æœ€ä½³ç»“æœ:")
    print(f"  - æœ€é«˜å‡†ç¡®ç‡: {best_acc.method} ({best_acc.accuracy:.2%})")
    print(f"  - æœ€é«˜F1: {best_f1.method} ({best_f1.f1_macro:.4f})")
    print(f"  - æœ€å¿«è®­ç»ƒ: {fastest.method} ({fastest.train_time:.2f}s)")
    print(f"  - æœ€å°‘å‚æ•°: {smallest.method} ({smallest.n_parameters:,})")
    
    print(f"\nğŸ“ å¯è§£é‡Šæ€§å¯¹æ¯”:")
    for r in results:
        print(f"  - {r.method}: {r.interpretability}")
    
    # æ¨è
    print("\n" + "="*80)
    print("ğŸ’¡ æ¨èé€‰æ‹©")
    print("="*80)
    
    # ç»¼åˆè¯„åˆ†
    scores = {}
    for r in results:
        score = (
            r.accuracy * 0.3 +
            r.f1_macro * 0.3 +
            (1 - r.train_time / max(x.train_time for x in results)) * 0.1 +
            (1 - r.n_parameters / max(x.n_parameters for x in results)) * 0.1 +
            (0.8 if 'KAN' in r.method else 0.5 if 'PINN' in r.method else 0.2) * 0.2  # å¯è§£é‡Šæ€§åŠ åˆ†
        )
        scores[r.method] = score
    
    best_overall = max(scores.items(), key=lambda x: x[1])
    print(f"\nç»¼åˆæ¨è: {best_overall[0]} (ç»¼åˆå¾—åˆ†: {best_overall[1]:.3f})")
    
    if 'PINN' in best_overall[0]:
        print("  ç†ç”±: ç‰©ç†çº¦æŸæå‡æ³›åŒ–èƒ½åŠ›ï¼Œæ®‹å·®å¯è§£é‡Šæ•…éšœæœºç†")
    elif 'KAN' in best_overall[0]:
        print("  ç†ç”±: 2024å¹´æœ€æ–°æ–¹æ³•ï¼Œå¯æå–ç¬¦å·è§„åˆ™ï¼Œå‚æ•°æ•ˆç‡é«˜")
    else:
        print("  ç†ç”±: ä¼ ç»Ÿæ–¹æ³•ï¼Œç®€å•å¯é ï¼Œé€‚åˆå¿«é€Ÿéƒ¨ç½²")


def main():
    """ä¸»å‡½æ•°"""
    print("="*80)
    print("ğŸ”¬ æŸ´æ²¹æœºæ•…éšœè¯Šæ–­æ¨¡å‹å¯¹æ¯”å®éªŒ")
    print("="*80)
    print("å¯¹æ¯”æ–¹æ³•: RandomForest (ä¼ ç»Ÿ) vs PINN (ç‰©ç†ä¿¡æ¯) vs KAN (2024)")
    print("-"*80)
    
    # ç”Ÿæˆæ•°æ®
    print("\nğŸ“¦ ç”Ÿæˆåˆæˆè¯Šæ–­æ•°æ®...")
    all_data = generate_synthetic_data(n_samples=2000, noise=0.1)
    
    # åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›† (80/20)
    n_train = int(len(all_data['labels']) * 0.8)
    indices = np.random.permutation(len(all_data['labels']))
    
    train_data = {
        'features': all_data['features'][indices[:n_train]],
        'physics': all_data['physics'][indices[:n_train]],
        'labels': all_data['labels'][indices[:n_train]]
    }
    test_data = {
        'features': all_data['features'][indices[n_train:]],
        'physics': all_data['physics'][indices[n_train:]],
        'labels': all_data['labels'][indices[n_train:]]
    }
    
    print(f"  è®­ç»ƒé›†: {len(train_data['labels'])} æ ·æœ¬")
    print(f"  æµ‹è¯•é›†: {len(test_data['labels'])} æ ·æœ¬")
    print(f"  ç±»åˆ«åˆ†å¸ƒ: {np.bincount(train_data['labels'])}")
    
    results = []
    
    # 1. RandomForest
    rf_result = train_random_forest(train_data, test_data)
    results.append(rf_result)
    
    # 2. PINN
    pinn_result = train_pinn(train_data, test_data, epochs=50)
    results.append(pinn_result)
    
    # 3. KAN
    kan_result = train_kan(train_data, test_data, epochs=50)
    results.append(kan_result)
    
    # å¯¹æ¯”ç»“æœ
    print_comparison_table(results)
    
    print("\n" + "="*80)
    print("âœ… è¯Šæ–­æ¨¡å‹å¯¹æ¯”å®éªŒå®Œæˆ!")
    print("="*80)


if __name__ == "__main__":
    main()
